{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse notebook foi utilizado para extrair os dados dos arquivos dbf que são criados por meio da expansão dos arquivos dbc fornecidos pelo DATASUS. A expansão dos arquivos dbc para dbf foi realizada com o software Tabwin do DATASUS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dbfread import DBF\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função que realiza a extração dos dados em arquivo dbf, aplica o filtro e seleção das colunas, e salva os dados em para excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processarArquivosDBF(pasta, name_save , colunas, tipo_arquivo=\".dbf\"):\n",
    "    caminhos = [os.path.join(pasta, nome) for nome in os.listdir(pasta)]\n",
    "    arquivos = [arq for arq in caminhos if os.path.isfile(arq)]\n",
    "    DBF_FILES = [arq for arq in arquivos if arq.lower().endswith(tipo_arquivo)]\n",
    "    \n",
    "    dfGlobal = pd.DataFrame(columns=colunas)\n",
    "    for dbf_file in DBF_FILES:\n",
    "        print('Lendo: ', dbf_file)\n",
    "        dbf = DBF(dbf_file, encoding='iso-8859-1')\n",
    "        frame_dbf = pd.DataFrame(iter(dbf))\n",
    "        frame_dbf = frame_dbf.loc[:,colunas]\n",
    "        dfGlobal = pd.concat([dfGlobal, frame_dbf], axis=0, ignore_index=True)#.reset_index()\n",
    "                \n",
    "    dfGlobal.to_csv(name_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leitura dos arquivos de Quimioterapia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### FINALIZADO ####\n"
     ]
    }
   ],
   "source": [
    "caminho_dbfs = '//AP_QI/DBF/'\n",
    "name_do_arquivo = 'QUIMIO.csv'\n",
    "colunas = ['AP_GESTAO','AP_AUTORIZ','AP_CMP','AP_PRIPAL','AP_UFMUN','AP_NUIDADE','AP_SEXO','AP_TPATEN','AP_TPAPAC','AP_DTSOLIC','AP_CIDPRI','AQ_ESTADI','AQ_ESQU_P2']\n",
    "\n",
    "processarArquivosDBF(caminho_dbfs, name_do_arquivo, colunas, tipo_arquivo=\".dbf\")\n",
    "\n",
    "print('#### FINALIZADO ####')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leitura dos arquivos de Radioterapia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### FINALIZADO ####\n"
     ]
    }
   ],
   "source": [
    "caminho_dbfs = '//AP_RAD/DBF/'\n",
    "name_do_arquivo = 'RADIO.csv'\n",
    "colunas = ['AP_GESTAO','AP_AUTORIZ','AP_CMP','AP_PRIPAL','AP_UFMUN','AP_NUIDADE','AP_SEXO','AP_TPAPAC','AP_DTSOLIC','AP_CIDPRI','AR_ESTADI','AR_FINALI']\n",
    "\n",
    "processarArquivosDBF(caminho_dbfs, name_do_arquivo, colunas, tipo_arquivo=\".dbf\")\n",
    "\n",
    "print('#### FINALIZADO ####')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leitura dos arquivos de Cirurgia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processarArquivosDBF_Cirurgia(pasta, name_save , colunas, tipo_arquivo=\".dbf\"):\n",
    "    caminhos = [os.path.join(pasta, nome) for nome in os.listdir(pasta)]\n",
    "    arquivos = [arq for arq in caminhos if os.path.isfile(arq)]\n",
    "    DBF_FILES = [arq for arq in arquivos if arq.lower().endswith(tipo_arquivo)]\n",
    "    \n",
    "    dfGlobal = pd.DataFrame(columns=colunas)\n",
    "    for dbf_file in DBF_FILES:\n",
    "        print('Lendo: ', dbf_file)\n",
    "        dbf = DBF(dbf_file, encoding='iso-8859-1')\n",
    "        frame_dbf = pd.DataFrame(iter(dbf))\n",
    "        frame_dbf = frame_dbf.loc[:,colunas]\n",
    "        filtro = (frame_dbf.PROC_REA =='0416120024') | (frame_dbf.PROC_REA=='0416120032') | (frame_dbf.PROC_REA=='0416120040') | (frame_dbf.PROC_REA=='0416120059')\n",
    "        frame_dbf = frame_dbf[filtro]\n",
    "        dfGlobal = pd.concat([dfGlobal, frame_dbf], axis=0, ignore_index=True)#.reset_index()\n",
    "                \n",
    "    dfGlobal.to_csv(name_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### FINALIZADO ####\n"
     ]
    }
   ],
   "source": [
    "caminho_dbfs = '//RD_CIR/DBF/'\n",
    "name_do_arquivo = 'CIRURGIA.csv'\n",
    "colunas = ['UF_ZI','ANO_CMPT','MES_CMPT','N_AIH','NASC','SEXO','PROC_SOLIC','PROC_REA','DT_INTER','DIAG_PRINC','IDADE','COMPLEX']\n",
    "\n",
    "processarArquivosDBF_Cirurgia(caminho_dbfs, name_do_arquivo, colunas, tipo_arquivo=\".dbf\")\n",
    "\n",
    "print('#### FINALIZADO ####')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
